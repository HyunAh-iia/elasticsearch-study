# Contents

## 1. 엘라스틱서치를 구성하는 개념

### 기본 용어
    - 인덱스(index)
        - 데이터 저장 공간
        - 하나의 인덱스는 하나의 타입만 가지며 하나의 물리적인 노드에 여러 개의 논리적인 인덱스 생성 가능
        - 검색 시 인덱스 이름으로 문서 데이터를 검색하며, 여러 개의 인덱스를 동시에 검색하는 것도 가능
        - 인덱스 생성 시 기본적으로 5개의 프라이머리 샤드와 1개의 레플리카 샤드 세트를 생성
        - 인덱스 이름은 모두 소문자
        - 인덱스가 없는 상태에서 데이터가 추가된다면 데이터를 이용해 인덱스가 자동으로 생성됨 (!실습해보기)
    - 샤드(shard)
        - 색인된 문서는 하나의 인덱스에 담김
        - 색인된 데이터는 물리적인 공간에 여러 개의 파티션으로 나뉘어 구성디는데, 이 파티션을 샤드라 부름
    - 타입(type)
        - 인덱스의 논리적 구조를 의미
        - 엘라스틱 6.1 버전 부터는 인덱스당 하나의 타입만 사용 가능
    - 문서(document)
        - 데이터가 저장되는 최소 단위
        - RDB 테이블의 row에 해당함
    - 필드(Field)
        - 문서를 구성하기 위한 속성
        - 하나의 필드는 목적에 따라 다수의 데이터 타입을 가질 수 있음
        - 예를 들어, 영화 제목을 검색할 때 매칭 검색을 하거나 초성을 이용한 검색이 모두 지원되도록 제목 필드는 2개의 데이터 타입을 갖게 할 수 있다.
### 노드의 종류
    - 클러스터는 물리적인 노드 인스턴스들의 모임
    - 모든 노드의 검색과 색인 작업을 관장하는 논리적인 개념
    - 엘라스틱서치는 각 설정에 따라 4가지 유형의 노드 제공
    - 각 노드는 한 가지 유형으로 동작할 수도 있고, 여러 개의 유형을 겸해서 동작할 수 있음
    - 마스터 노드(master node)
        - 클러스터 관리
        - 노드 추가 및 제거와 같은 클러스터의 전반적인 관리 담당
        - 네트워크 속도가 빠르고 지연이 없는 노드를 마스터 노드로 선정
        - 다수의 노드를 마스터 노드로 설정할 수 있지만, 결과적으로 하나의 노드만이 마스터 노드로 선출되어 동작
    - 데이터 노드(data node)
        - 실질적인 데이터 저장
        - 검색과 통계 같은 데이터 관련 작업 수행
        - 색인 작업은 CPU, 메모리, 스토리지 같은 컴퓨팅 리소스를 많이 소모하기 때문에 리소스 모니터링 필요
        - 데이터 노드는 가능한 마스터 노드와 분리해서 구성하는 것을 권장 (문서 수가 너무 적으면 함께해도 괜찮음)
    - 코디네이팅 노드(coordination node)
        - 사용자의 요청만 받아서 처리
        - 클러스터 관련 요청은 마스터 노드에 전달하고 데이터 관련 요청은 데이터 노드에 전달
        - 데이터 노드, 마스터노드, 인제스트 노드의 역할을 하지 않고, 들어온 요청을 단순히 라운드로빈 방식으로 분산시킴
    - 인제스트 노드(ingest node)
        - 색인 전 문서의 전처리 작업 담당
        - 인덱스 생성 전 문서의 형식을 다양하게 변경 가능
        - 데이터의 포맷을 변경하기 위해 스크립트로 전처리 파이프라인을 구성하고 실행 가능
### 클러스터, 샤드, 노드
    - 엘라스틱서치 클러스터는 인덱스의 문서를 조회할 때 마스터 노드를 통해 N개의 노드를 모두 조회해서 각 데이터를 취합한 후 결과를 하나로 합쳐서 제공함
    - 여러 개의 클러스터를 연결해서 구성할 수도 있으며, 이 때는 클러스터의 이름으로 각각을 구분함
    - 클러스터에 있는 노드는 실시간으로 추가, 제거가 가능하기 때문에 가용성이나 확장성 측면에서 매우 유연
    - 장애가 발생하면 마스터 노드는 데이터를 재분배하거나 레플리카 샤드를 프라이머리 샤드로 승격시켜 서비스 중단 없는 복구 가능
    - 장애극복(Failover) 상황을 염두에 두고 노드와 샤드의 수를 적절히 구성

## 2. 엘라스틱서치에서 제공하는 주요 API
### 인덱스 관리 API
    - 인덱스 생성
        - 한번 생성된 매핑 정보는 변경할 수 없다.
        - ```
            //요청
            PUT /인덱스명
            {
              "setting": {
                샤딩 정보
              },
              "mapping": {
                "_doc": {
                  "propferties": {
                    "컬럼명": { "type" : "integer/text/date/keyword/date" }
                  }
                }
              }
            }

          //응답
          {
            "acknowledged": true,
            "shards_acknowledged": true,
            "index": "인덱스명"
          }
          ```
    - 인덱스 삭제
        - DELETE 메서드를 통해 삭제 가능
        - 인덱스를 한번 삭제하면 복구 불가능함
        - ```
          // 요청
          DELETE /인덱스명

          // 응답
          {
            "acknowledged": false
          }
          ```
### 문서 관리 API
    - 단건 처리(Single document API)
        - index API : 한 건의 문서 색인
            - ```
              POST /인덱스명/_doc/문서ID
              {
              }
              ```
        - GET API : 한 건의 문서 조회
            - ```
              GET /인덱스명/_doc/문서ID
              ```
        - DELETE API : 한 건의 문서 삭제
            - ```
              DELETE /인덱스명/_doc/문서ID
              ```
        - Update API : 책에 내용이 없어서 따로 찾음
            - ```
              POST /인덱스명/_update/문서ID
              {
              }
              ```
        - ID를 지정하지 않고 문서를 생성
            - ID를 지정하지 않는 경우 _id에 UUID 무작위로 생성됨
            - 무작위로 생성된 _id 값은 해당 문서를 업데이트 할 때 애로사항 발생
            - 엘라스틱서치에 색인된 _id 값과 데이터베이스의 PK를 매칭한 정보를 어딘가에 관리해야함
            - 색인된 문서의 _id 값은 업데이트를 고려해서 데이터베이스 테이블의 식별 값과 맞추는 것이 운영에 편리
            - (그런데 ES에서 자동으로 생성해주는 UUID _id값이 아니라 논리적인 key값을 사용하면 버그가 있음, ES 운영 안해봐서 어떤 버그인지는 모르겠음)
    - 다건 처리(Multi-document API)
        - Multi Get API : 다수의 문서 조회
        - Bulk API : ㄷ량의 문서 색인
        - Delete By Query API : 다수의 문서 삭제
        - Update By Query API : 다수의 문서 업데이트
        - Reindex API : 인덱스의 문서를 다시 색인
### 검색 API
    - URI 검색방법 : HTTP URL 형태의 파라미터를 URI에 추가해 검색
        - URI 방식은 간단한 쿼리나 디버깅할 때 간편하게 사용하고자 할 때 이용됨
        - 예제
            - ```
              // GET 메서드 이용
              GET /인덱스명/_doc/1?pretty=true

              // q 파라미터를 사용해 해당 단어와 일치하는 문서만 조회
              //
              POST /인덱스명/_search?q=장편

              ```
        - 검색 결과의 _shards에서는 성공적으로 반환한 샤드의 수와 실패한 샤드의 수를 알 수 있다.
        - hits에서는 일치하는 문서의 수와 함께 점수(_score)가 가장 높은 상위 10개의 문서를 보여줌
        - q파라미터를 사용할 때 별도의 필드명을 지정하지 않으면 존재하는 모든 필드를 대상으로 검색 수행
        - 특정 필드만 조회를 원할 경우 ?q=typeNm:장편
    - Request Body 검색방법 : RESTful API 방식인 QueryDSL을 사용해 요청 본문(request body)에 질의 내용을 추가해 검색
        - Request Body 방식은 URI 방식보다 제약사항이 적기 때문에 현업에서 선호함
        - 예제
            - ```
              // 기본 구문
              POST /인덱스명/_search
              {
              JSON 쿼리 구문
              }

              // JSON 쿼리 구문에 사용 가능한 속성
              {
                "size": 몇 개의 결과를 반환할지 결정 (기본값 10),
                "from": 어느 위치부터 반환할지 결정. 0부터 시작하면 상위 0~10건의 데이터 반환 (기본값 0),
                "_source": 특정 필드만 결과로 반환하고자 할 때 사용,
                "sort": 특정 필드를 기준으로 정렬 (ase, desc)
                "query": {
                    검색될 조건 정의
                },
                "filter": {
                    검색 결과 중 특정한 값을 다시 보여줌
                    결과 내에서 재검색할 때 사용하는 기능 중 하나
                    필터를 사용하게 되면 자동으로 score 값이 정렬되지 않음
                }
              }
              ```
### 집계 API
    - 통계 작업을 위해 엘라스틱서치에서 제공하는 기능
        - 패싯(Facets)기능
            - 과거에는 패싯 기능을 많이 활용
            - 기본적으로 디스크 기반으로 동작했기 떄문에, 분산 환경에 최적화되지 않아 대용량 데이터의 통계 작업에는 적합하지 않음
            - 이로 인해 많은 장애 발생
            - 엘라스틱서치 5.0 이후에 패싯 방식의 통계 기능을 제거
        - 집계(Aggregation) API
            - 기본적으로 메모리 기반으로 동작하기 때문에 대용량의 데이터 통계 작업 가능
    - 데이터 집계
        - _search API를 사용해 집계 쿼리를 만들고 terms 키워드를 이용해 genreAlt라는 필드의 데이터를 그릅화
            - ```
              POST /인덱스명/_search?size=0
              {
                "aggs":{
                    "genre":{
                        "terms":{
                            "field":"genreAlt"
                        }
                    }
                }
              }
              ```
            - genreAlt 필드 그릅화한 결과가 나옴
            - size=0으로 한 이유는 집계 결과만 보려고 검색 적중을 표시하지 않도록 한 것임
            - 결과 중 흥미로운 속성
                - "doc_count_error_upper_bound" : 문서 수에 대한 오류 상한선
                - "sum_other_doc_count" : 결과에 포함되지 않은 문서 수 (size를 늘리면 된다)
                - "Buckets" : 버킷이라는 구조 안에 그룹화된 데이터가 포함돼 있다.
        - 데이터 집계 타입
            - 버킷 집계(Bucket Aggregation)
                - 집계 중 가장 많이 사용함
                - 문서의 필드 기준으로 버킷 집계
            - 메트릭 집계(Metric Aggregation)
                - 문서에서 추출된 값을 가지고 sum, max, min, avg 계산
            - 매트릭스 집계(Matrix Aggregation)
                - 행렬의 값을 합하거나 곱함
            - 파이프라인 집계(Pipeline Aggregation)
                - 버킷에서 도출된 결과 문서를 다른 필드 값으로 재분류
                - 즉, 다른 집계에 의해 생성된 출력 결과를 다시 한번 집계
                - 집계가 패싯보다 강력한 이유가 여기 있음

### 스키마리스는 가능하면 사용하지 말자
    - 스키마리스란? 인덱스 생성하는 과정 없이 문서를 추가하더라도 문서가 색인되도록 지원하는 일종의 편의 기능이다.
    - 책에서는 아래와 같은 이유로 사용하지 말 것을 권한다.
        1. 데이터 공간의 낭비 초래 : 기본적으로 모든 피드가 text, keyword 타입을 동시 제공하는 멀티필드 기능으로 구성
        2. 품질이 떨어지거나 성능상 이슈
            - 스키마리스를 이용해 색인한다면 기본적으로 text타입의 Standard Analyzer를 사용함
            - 원하는 결과를 얻기 위해서는 한글 형태소 분석하는 분석기를 사용하도록 데이터를 직접 정의해야함
            - 원하는 결과를 얻기 위해서라도 스키마리스 방식의 사용을 지양하고 반드시 인덱스를 직접 정의해서 사용하는 습관 필요
    - 스키마리스 기능을 명시적으로 사용하지 않도록 설정 가능
        - 노드 설정 파일에서 action.auto_Create_index를 false로 설정 (자동으로 인덱스 생성 비활성화)
        - 인덱스별로 제공되는 index.mapper.dynamic을 false로 설정 (특정 컬럼의 자동 매핑 생성 비활성화)